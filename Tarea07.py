# TAREA 7 - Machine Learning
# OPERACI√ìN 01: Red Neuronal con Fashion MNIST
# OPERACI√ìN 02: Regresi√≥n Lineal Simple

# =============================================================================
# OPERACI√ìN 01: Crear y entrenar una red neuronal con Python y TensorFlow
# =============================================================================

print("=" * 70)
print("OPERACI√ìN 01: RED NEURONAL CON FASHION MNIST")
print("=" * 70)

# Paso 1: Importar las bibliotecas necesarias
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.datasets import fashion_mnist
import matplotlib.pyplot as plt
import numpy as np

print(f"\nTensorFlow versi√≥n: {tf.__version__}")

# Paso 2: Cargar y Explorar el Conjunto de Datos Fashion MNIST
print("\n--- Paso 2: Cargando el dataset Fashion MNIST ---")
(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()

print(f"Datos de entrenamiento: {X_train.shape}")
print(f"Etiquetas de entrenamiento: {y_train.shape}")
print(f"Datos de prueba: {X_test.shape}")
print(f"Etiquetas de prueba: {y_test.shape}")

# Definir las etiquetas de las categor√≠as
labels = ["T-shirt/top", "Trouser", "Pullover", "Dress", "Coat", 
          "Sandal", "Shirt", "Sneaker", "Bag", "Ankle boot"]

# Visualizar algunas im√°genes del dataset
print("\n--- Visualizando muestras del dataset ---")
plt.figure(figsize=(14, 8))
for i in range(20):
    plt.subplot(4, 5, i+1)
    plt.imshow(X_train[i], cmap="binary")
    plt.title(labels[y_train[i]])
    plt.axis("off")
plt.tight_layout()
plt.show()

# Paso 3: Normalizaci√≥n de Datos
print("\n--- Paso 3: Normalizando los datos ---")
X_train_norm = X_train / 255.0
X_test_norm = X_test / 255.0
print("Datos normalizados al rango [0, 1]")

# Paso 4: Definici√≥n de la Arquitectura de la Red Neuronal
print("\n--- Paso 4: Definiendo la arquitectura de la red neuronal ---")
model = keras.Sequential([
    keras.layers.Flatten(input_shape=(28, 28)),
    keras.layers.Dense(128, activation='relu'),
    keras.layers.Dense(10, activation='softmax')
])

# Mostrar resumen del modelo
model.summary()

# Paso 5: Compilar el Modelo
print("\n--- Paso 5: Compilando el modelo ---")
model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)
print("Modelo compilado exitosamente")

# Paso 6: Entrenar el Modelo
print("\n--- Paso 6: Entrenando el modelo (30 √©pocas) ---")
history = model.fit(
    X_train_norm, 
    y_train, 
    epochs=30, 
    validation_data=(X_test_norm, y_test),
    verbose=1
)

# Visualizar el progreso del entrenamiento
plt.figure(figsize=(12, 4))

plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Precisi√≥n entrenamiento')
plt.plot(history.history['val_accuracy'], label='Precisi√≥n validaci√≥n')
plt.xlabel('√âpoca')
plt.ylabel('Precisi√≥n')
plt.legend()
plt.title('Precisi√≥n durante el entrenamiento')
plt.grid(True)

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='P√©rdida entrenamiento')
plt.plot(history.history['val_loss'], label='P√©rdida validaci√≥n')
plt.xlabel('√âpoca')
plt.ylabel('P√©rdida')
plt.legend()
plt.title('P√©rdida durante el entrenamiento')
plt.grid(True)

plt.tight_layout()
plt.show()

# Paso 7: Evaluar el Modelo
print("\n--- Paso 7: Evaluando el modelo ---")
test_loss, test_acc = model.evaluate(X_test_norm, y_test, verbose=0)
print(f'\nPrecisi√≥n en el conjunto de prueba: {test_acc:.4f} ({test_acc*100:.2f}%)')
print(f'P√©rdida en el conjunto de prueba: {test_loss:.4f}')

# Hacer algunas predicciones de ejemplo
print("\n--- Predicciones de ejemplo ---")
predictions = model.predict(X_test_norm[:10])

plt.figure(figsize=(15, 3))
for i in range(10):
    plt.subplot(2, 5, i+1)
    plt.imshow(X_test[i], cmap="binary")
    predicted_label = labels[np.argmax(predictions[i])]
    true_label = labels[y_test[i]]
    color = 'green' if predicted_label == true_label else 'red'
    plt.title(f"Real: {true_label}\nPredicho: {predicted_label}", color=color, fontsize=9)
    plt.axis("off")
plt.tight_layout()
plt.show()

# =============================================================================
# OPERACI√ìN 02: Implementar y graficar regresi√≥n lineal simple
# =============================================================================

print("\n" + "=" * 70)
print("OPERACI√ìN 02: REGRESI√ìN LINEAL SIMPLE")
print("=" * 70)

# Importar bibliotecas adicionales
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
from scipy.spatial.distance import cdist

print("\n--- An√°lisis de relaci√≥n entre Temperatura y Ventas ---")

# Datos de ejemplo (ficticios)
temperatura = np.array([15, 16, 18, 20, 21, 23, 25, 27, 30, 32])
ventas = np.array([500, 520, 560, 580, 600, 640, 680, 700, 760, 800])

print(f"Datos de temperatura: {temperatura}")
print(f"Datos de ventas: {ventas}")

# Dividir los datos en conjunto de entrenamiento y prueba
X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(
    temperatura.reshape(-1, 1), 
    ventas,
    test_size=0.2, 
    random_state=42
)

print(f"\nDatos de entrenamiento: {len(X_train_reg)}")
print(f"Datos de prueba: {len(X_test_reg)}")

# Crear y entrenar el modelo de regresi√≥n lineal
reg_model = LinearRegression()
reg_model.fit(X_train_reg, y_train_reg)

print(f"\n--- Par√°metros del modelo ---")
print(f"Coeficiente (pendiente): {reg_model.coef_[0]:.2f}")
print(f"Intercepto: {reg_model.intercept_:.2f}")
print(f"Ecuaci√≥n: Ventas = {reg_model.coef_[0]:.2f} * Temperatura + {reg_model.intercept_:.2f}")

# Hacer predicciones
y_pred_train = reg_model.predict(X_train_reg)
y_pred_test = reg_model.predict(X_test_reg)

# Evaluaci√≥n del modelo
r_sq = reg_model.score(X_test_reg, y_test_reg)
mse = mean_squared_error(y_test_reg, y_pred_test)
rmse = np.sqrt(mse)

print(f"\n--- M√©tricas de evaluaci√≥n ---")
print(f'Coeficiente de determinaci√≥n (R¬≤): {r_sq:.4f}')
print(f'Error cuadr√°tico medio (MSE): {mse:.2f}')
print(f'Ra√≠z del error cuadr√°tico medio (RMSE): {rmse:.2f}')

# Gr√°fica de resultados
plt.figure(figsize=(10, 6))
plt.scatter(temperatura, ventas, color="blue", s=100, alpha=0.6, label="Datos reales", zorder=3)
plt.plot(temperatura, reg_model.predict(temperatura.reshape(-1, 1)), 
         color="red", linewidth=2, label="L√≠nea de regresi√≥n", zorder=2)
plt.scatter(X_test_reg, y_test_reg, color="green", s=150, marker='s', 
            alpha=0.8, label="Datos de prueba", zorder=4)
plt.xlabel("Temperatura (¬∞C)", fontsize=12)
plt.ylabel("Ventas", fontsize=12)
plt.title("Regresi√≥n Lineal: Temperatura vs Ventas", fontsize=14, fontweight='bold')
plt.legend(fontsize=10)
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

# An√°lisis de residuos
residuos = y_test_reg - y_pred_test
plt.figure(figsize=(10, 4))

plt.subplot(1, 2, 1)
plt.scatter(y_pred_test, residuos, color='purple', alpha=0.6)
plt.axhline(y=0, color='red', linestyle='--', linewidth=2)
plt.xlabel('Valores predichos')
plt.ylabel('Residuos')
plt.title('Gr√°fico de Residuos')
plt.grid(True, alpha=0.3)

plt.subplot(1, 2, 2)
plt.hist(residuos, bins=5, color='orange', alpha=0.7, edgecolor='black')
plt.xlabel('Residuos')
plt.ylabel('Frecuencia')
plt.title('Distribuci√≥n de Residuos')
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# =============================================================================
# APLICACIONES PR√ÅCTICAS ADICIONALES
# =============================================================================

print("\n" + "=" * 70)
print("APLICACIONES PR√ÅCTICAS EN LA INDUSTRIA DE LA MODA")
print("=" * 70)

# -----------------------------------------------------------------------------
# OPCI√ìN: Clasificar TUS PROPIAS IM√ÅGENES
# -----------------------------------------------------------------------------
print("\n" + "=" * 70)
print("üñºÔ∏è CLASIFICAR TUS PROPIAS IM√ÅGENES")
print("=" * 70)
print("\nPuedes subir tus propias im√°genes de ropa para clasificar:")
print("1. Ejecuta la celda de c√≥digo de abajo")
print("2. Haz clic en 'Choose Files' y selecciona una imagen")
print("3. El modelo clasificar√° autom√°ticamente la prenda\n")

# C√≥digo para subir y clasificar imagen propia
try:
    from google.colab import files
    from PIL import Image
    import io
    
    print("üì§ Sube una imagen de ropa (formato: JPG, PNG):")
    uploaded = files.upload()
    
    if uploaded:
        # Procesar cada imagen subida
        for filename, file_data in uploaded.items():
            print(f"\n--- Procesando: {filename} ---")
            
            # Cargar y preprocesar la imagen
            img = Image.open(io.BytesIO(file_data))
            
            # Mostrar imagen original
            plt.figure(figsize=(12, 4))
            
            plt.subplot(1, 3, 1)
            plt.imshow(img)
            plt.title("Imagen Original", fontweight='bold')
            plt.axis('off')
            
            # Convertir a escala de grises y redimensionar a 28x28
            img_gray = img.convert('L')
            img_resized = img_gray.resize((28, 28))
            img_array = np.array(img_resized)
            
            plt.subplot(1, 3, 2)
            plt.imshow(img_resized, cmap='binary')
            plt.title("Procesada (28x28)", fontweight='bold')
            plt.axis('off')
            
            # Normalizar y preparar para predicci√≥n
            img_normalized = img_array / 255.0
            img_input = img_normalized.reshape(1, 28, 28)
            
            # Hacer predicci√≥n
            prediction = model.predict(img_input, verbose=0)
            predicted_class = np.argmax(prediction)
            confidence = np.max(prediction) * 100
            
            # Mostrar predicci√≥n
            plt.subplot(1, 3, 3)
            plt.barh(labels, prediction[0], color='skyblue')
            plt.xlabel('Probabilidad', fontweight='bold')
            plt.title('Predicci√≥n del Modelo', fontweight='bold')
            plt.xlim(0, 1)
            
            # Destacar la predicci√≥n m√°s alta
            max_idx = np.argmax(prediction[0])
            plt.barh(labels[max_idx], prediction[0][max_idx], color='green')
            
            plt.tight_layout()
            plt.show()
            
            print(f"\nüéØ RESULTADO:")
            print(f"   Categor√≠a predicha: {labels[predicted_class]}")
            print(f"   Confianza: {confidence:.2f}%")
            
            if confidence < 70:
                print(f"   ‚ö†Ô∏è Baja confianza - La imagen podr√≠a no ser clara o no pertenecer a estas categor√≠as")
            
            print("\nüìä Top 3 predicciones:")
            top_3_idx = np.argsort(prediction[0])[-3:][::-1]
            for i, idx in enumerate(top_3_idx, 1):
                print(f"   {i}. {labels[idx]:15s} - {prediction[0][idx]*100:.2f}%")
    else:
        print("‚ùå No se subi√≥ ninguna imagen")
        
except ImportError:
    print("‚ÑπÔ∏è Esta funcionalidad solo est√° disponible en Google Colab")
    print("   Si est√°s en Colab, contin√∫a con las aplicaciones de demostraci√≥n abajo.")
    print("   Si est√°s en local, puedes modificar esta secci√≥n para cargar im√°genes locales.")

print("\n" + "=" * 70)

# -----------------------------------------------------------------------------
# APLICACI√ìN 1: B√∫squeda Visual por Similitud de Imagen
# -----------------------------------------------------------------------------
print("\n--- APLICACI√ìN 1: B√∫squeda Visual por Similitud Real ---")
print("Encontrar productos visualmente similares usando caracter√≠sticas de la red\n")

# Seleccionar una imagen de prueba como "b√∫squeda"
search_image_idx = 42
search_image = X_test_norm[search_image_idx]
search_label_real = labels[y_test[search_image_idx]]

print(f"üîç Producto de b√∫squeda: {search_label_real}")

# M√âTODO 1: Extracci√≥n de caracter√≠sticas con la red neuronal
# Creamos un modelo que extrae las caracter√≠sticas de la capa oculta
# Primero necesitamos construir el modelo si no ha sido llamado
if not model.built:
    model.build(input_shape=(None, 28, 28))

# Crear extractor de caracter√≠sticas usando la arquitectura interna
feature_extractor = keras.Sequential([
    model.layers[0],  # Flatten
    model.layers[1]   # Dense de 128 neuronas
])

print("Extrayendo caracter√≠sticas visuales de todas las im√°genes...")
# Extraer caracter√≠sticas de la imagen de b√∫squeda
search_features = feature_extractor.predict(search_image.reshape(1, 28, 28), verbose=0)

# Extraer caracter√≠sticas de todas las im√°genes de prueba (en lotes para eficiencia)
print("Procesando conjunto de prueba...")
all_features = feature_extractor.predict(X_test_norm, verbose=0, batch_size=256)

# Calcular similitud usando distancia euclidiana
from scipy.spatial.distance import cdist

# Calcular distancias entre la imagen de b√∫squeda y todas las dem√°s
distances = cdist(search_features, all_features, metric='euclidean')[0]

# Ordenar por similitud (menor distancia = m√°s similar)
similar_indices = np.argsort(distances)[1:7]  # Excluir la imagen misma (√≠ndice 0)
similarities = 1 / (1 + distances[similar_indices])  # Convertir distancia a similitud

print(f"‚úì B√∫squeda completada usando caracter√≠sticas de la red neuronal\n")

# M√âTODO 2 (Adicional): Similitud de p√≠xeles directa
print("M√©todo alternativo: Similitud directa de p√≠xeles...")
pixel_distances = np.sum(np.abs(X_test_norm - search_image), axis=(1, 2))
pixel_similar_indices = np.argsort(pixel_distances)[1:7]

plt.figure(figsize=(16, 8))

# === M√âTODO 1: B√∫squeda por Caracter√≠sticas (Red Neuronal) ===
plt.subplot(2, 7, 1)
plt.imshow(X_test[search_image_idx], cmap="binary")
plt.title(f"B√öSQUEDA\n{search_label_real}", fontweight='bold', color='blue', fontsize=10)
plt.axis("off")
plt.gca().add_patch(plt.Rectangle((-0.5, -0.5), 28, 28, fill=False, 
                                   edgecolor='blue', linewidth=3))

for i, idx in enumerate(similar_indices):
    plt.subplot(2, 7, i+2)
    plt.imshow(X_test[idx], cmap="binary")
    
    item_label = labels[y_test[idx]]
    similarity_score = similarities[i] * 100
    
    # Color seg√∫n si es la misma categor√≠a o no
    is_same_category = y_test[idx] == y_test[search_image_idx]
    border_color = 'green' if is_same_category else 'orange'
    title_color = 'green' if is_same_category else 'darkorange'
    
    plt.title(f"{item_label}\nSim: {similarity_score:.1f}%", 
              fontsize=8, color=title_color)
    plt.axis("off")
    plt.gca().add_patch(plt.Rectangle((-0.5, -0.5), 28, 28, fill=False, 
                                       edgecolor=border_color, linewidth=2))

# === M√âTODO 2: B√∫squeda por P√≠xeles ===
plt.subplot(2, 7, 8)
plt.imshow(X_test[search_image_idx], cmap="binary")
plt.title(f"B√öSQUEDA\n{search_label_real}", fontweight='bold', color='purple', fontsize=10)
plt.axis("off")
plt.gca().add_patch(plt.Rectangle((-0.5, -0.5), 28, 28, fill=False, 
                                   edgecolor='purple', linewidth=3))

for i, idx in enumerate(pixel_similar_indices):
    plt.subplot(2, 7, i+9)
    plt.imshow(X_test[idx], cmap="binary")
    
    item_label = labels[y_test[idx]]
    
    is_same_category = y_test[idx] == y_test[search_image_idx]
    border_color = 'green' if is_same_category else 'orange'
    title_color = 'green' if is_same_category else 'darkorange'
    
    plt.title(f"{item_label}", fontsize=8, color=title_color)
    plt.axis("off")
    plt.gca().add_patch(plt.Rectangle((-0.5, -0.5), 28, 28, fill=False, 
                                       edgecolor=border_color, linewidth=2))

plt.suptitle("B√∫squeda Visual por Similitud de Imagen\n" +
             "Arriba: Caracter√≠sticas de Red Neuronal | Abajo: Similitud de P√≠xeles", 
             fontsize=13, fontweight='bold')
plt.tight_layout()
plt.show()

# Mostrar estad√≠sticas comparativas
print("=" * 70)
print("COMPARACI√ìN DE M√âTODOS DE B√öSQUEDA")
print("=" * 70)

print("\nüìä M√©todo 1 - Caracter√≠sticas de Red Neuronal (Recomendado):")
same_cat_count = sum([y_test[idx] == y_test[search_image_idx] for idx in similar_indices])
print(f"   Productos de la misma categor√≠a: {same_cat_count}/6 ({same_cat_count/6*100:.1f}%)")
print(f"   Ventaja: Captura patrones sem√°nticos de alto nivel")

print("\nüìä M√©todo 2 - Similitud Directa de P√≠xeles:")
pixel_same_cat_count = sum([y_test[idx] == y_test[search_image_idx] for idx in pixel_similar_indices])
print(f"   Productos de la misma categor√≠a: {pixel_same_cat_count}/6 ({pixel_same_cat_count/6*100:.1f}%)")
print(f"   Ventaja: M√°s simple, busca por apariencia visual directa")

print("\nüí° Interpretaci√≥n:")
if same_cat_count >= pixel_same_cat_count:
    print("   La b√∫squeda por caracter√≠sticas de red neuronal es m√°s efectiva")
    print("   porque entiende el 'significado' de la imagen, no solo los p√≠xeles")
else:
    print("   La b√∫squeda por p√≠xeles funciona bien para este caso")
    print("   pero puede fallar con variaciones de iluminaci√≥n o pose")

print("\nüîç Resultados detallados (M√©todo por Red Neuronal):")
for i, idx in enumerate(similar_indices, 1):
    item_label = labels[y_test[idx]]
    similarity_score = similarities[i-1] * 100
    match = "‚úì" if y_test[idx] == y_test[search_image_idx] else "‚úó"
    print(f"   {i}. {item_label:15s} - Similitud: {similarity_score:5.1f}% {match}")

# -----------------------------------------------------------------------------
# APLICACI√ìN 2: Control de Calidad Autom√°tico
# -----------------------------------------------------------------------------
print("\n--- APLICACI√ìN 2: Control de Calidad Autom√°tico ---")
print("Detectar posibles defectos o clasificaciones incorrectas\n")

# Simular control de calidad: encontrar predicciones con baja confianza
all_predictions = model.predict(X_test_norm, verbose=0)
confidence_scores = np.max(all_predictions, axis=1)

# Umbral de confianza para alertas de calidad
quality_threshold = 0.85
low_confidence_idx = np.where(confidence_scores < quality_threshold)[0][:8]

if len(low_confidence_idx) > 0:
    plt.figure(figsize=(16, 4))
    
    for i, idx in enumerate(low_confidence_idx):
        plt.subplot(2, 4, i+1)
        plt.imshow(X_test[idx], cmap="binary")
        
        predicted_label = labels[np.argmax(all_predictions[idx])]
        true_label = labels[y_test[idx]]
        confidence = confidence_scores[idx]
        
        color = 'orange' if confidence < 0.7 else 'yellow'
        plt.title(f"Confianza: {confidence:.2%}\nReal: {true_label}\nPred: {predicted_label}", 
                  fontsize=8, color=color)
        plt.axis("off")
        
        if confidence < 0.7:
            plt.gca().add_patch(plt.Rectangle((-0.5, -0.5), 28, 28, fill=False, 
                                               edgecolor='red', linewidth=2))
    
    plt.suptitle("‚ö†Ô∏è Control de Calidad: Productos Requieren Inspecci√≥n Manual", 
                 fontsize=14, fontweight='bold')
    plt.tight_layout()
    plt.show()
    
    print(f"‚ö†Ô∏è Alerta: {len(low_confidence_idx)} productos requieren revisi√≥n manual")
    print(f"   Confianza promedio: {np.mean(confidence_scores[low_confidence_idx]):.2%}")
else:
    print("‚úì Todos los productos cumplen con el est√°ndar de calidad")

# -----------------------------------------------------------------------------
# APLICACI√ìN 3: Gesti√≥n de Inventario Inteligente
# -----------------------------------------------------------------------------
print("\n--- APLICACI√ìN 3: Gesti√≥n de Inventario ---")
print("Clasificar y contar autom√°ticamente productos en almac√©n\n")

# Simular un lote de productos para clasificar
batch_size = 100
batch_indices = np.random.choice(len(X_test), batch_size, replace=False)
batch_images = X_test_norm[batch_indices]
batch_labels = y_test[batch_indices]

# Clasificar el lote completo
batch_predictions = model.predict(batch_images, verbose=0)
predicted_categories = np.argmax(batch_predictions, axis=1)

# Contar productos por categor√≠a
category_counts = {}
for i, category in enumerate(labels):
    count = np.sum(predicted_categories == i)
    category_counts[category] = count

# Visualizar distribuci√≥n del inventario
plt.figure(figsize=(14, 6))

plt.subplot(1, 2, 1)
categories = list(category_counts.keys())
counts = list(category_counts.values())
colors = plt.cm.Set3(np.linspace(0, 1, len(categories)))

bars = plt.bar(range(len(categories)), counts, color=colors, edgecolor='black', linewidth=1.5)
plt.xlabel('Categor√≠a de Producto', fontweight='bold')
plt.ylabel('Cantidad en Inventario', fontweight='bold')
plt.title('Distribuci√≥n de Inventario por Categor√≠a', fontweight='bold')
plt.xticks(range(len(categories)), categories, rotation=45, ha='right')
plt.grid(axis='y', alpha=0.3)

# Agregar valores en las barras
for bar in bars:
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2., height,
             f'{int(height)}', ha='center', va='bottom', fontweight='bold')

plt.subplot(1, 2, 2)
plt.pie(counts, labels=categories, autopct='%1.1f%%', colors=colors,
        startangle=90, textprops={'fontsize': 9, 'fontweight': 'bold'})
plt.title('Porcentaje del Inventario Total', fontweight='bold')

plt.tight_layout()
plt.show()

print(f"‚úì Clasificados {batch_size} productos autom√°ticamente:")
for category, count in sorted(category_counts.items(), key=lambda x: x[1], reverse=True):
    percentage = (count / batch_size) * 100
    bar = '‚ñà' * int(percentage / 2)
    print(f"  {category:15s}: {count:3d} unidades [{bar:20s}] {percentage:5.1f}%")

# -----------------------------------------------------------------------------
# APLICACI√ìN 4: Recomendaci√≥n de Outfits
# -----------------------------------------------------------------------------
print("\n--- APLICACI√ìN 4: Recomendaci√≥n de Outfits ---")
print("Sugerir combinaciones de prendas complementarias\n")

# Definir reglas de combinaci√≥n de outfits
outfit_rules = {
    'T-shirt/top': ['Trouser', 'Sneaker', 'Bag'],
    'Shirt': ['Trouser', 'Sneaker', 'Bag'],
    'Dress': ['Sandal', 'Bag', 'Coat'],
    'Pullover': ['Trouser', 'Sneaker', 'Bag'],
    'Coat': ['Shirt', 'Trouser', 'Ankle boot']
}

# Seleccionar una prenda base
base_item_idx = 15
base_image = X_test_norm[base_item_idx]
base_label = labels[y_test[base_item_idx]]

print(f"Prenda seleccionada: {base_label}")

# Generar recomendaciones
if base_label in outfit_rules:
    recommended_categories = outfit_rules[base_label]
    print(f"Recomendaciones: {', '.join(recommended_categories)}\n")
    
    plt.figure(figsize=(15, 4))
    
    # Mostrar prenda base
    plt.subplot(1, 4, 1)
    plt.imshow(X_test[base_item_idx], cmap="binary")
    plt.title(f"PRENDA BASE\n{base_label}", fontweight='bold', color='green', fontsize=11)
    plt.axis("off")
    plt.gca().add_patch(plt.Rectangle((-0.5, -0.5), 28, 28, fill=False, 
                                       edgecolor='green', linewidth=3))
    
    # Buscar y mostrar prendas complementarias
    for i, rec_category in enumerate(recommended_categories[:3]):
        # Encontrar √≠ndice de la categor√≠a recomendada
        cat_idx = labels.index(rec_category)
        # Buscar un producto de esa categor√≠a
        matching_indices = np.where(y_test == cat_idx)[0]
        
        if len(matching_indices) > 0:
            rec_idx = matching_indices[0]
            plt.subplot(1, 4, i+2)
            plt.imshow(X_test[rec_idx], cmap="binary")
            plt.title(f"Recomendaci√≥n {i+1}\n{rec_category}", fontsize=10)
            plt.axis("off")
    
    plt.suptitle("üí° Sistema de Recomendaci√≥n de Outfits", fontsize=14, fontweight='bold')
    plt.tight_layout()
    plt.show()
    
    print(f"‚úì Outfit completo sugerido con {len(recommended_categories)} prendas complementarias")
else:
    print(f"‚ö†Ô∏è No hay reglas de recomendaci√≥n para {base_label}")

print("\n" + "=" * 70)
print("TAREA COMPLETADA EXITOSAMENTE")
print("=" * 70)